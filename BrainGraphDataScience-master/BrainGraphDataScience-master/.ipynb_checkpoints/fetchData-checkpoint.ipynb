{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import threading\n",
    "import urllib\n",
    "class Parent (threading.Thread):\n",
    "\n",
    "    def __init__(self, htpLink, outputDir):\n",
    "        \"\"\"Documentation\"\"\"\n",
    "        threading.Thread.__init__(self)\n",
    "        self.source = htpLink\n",
    "        self.output = outputDir\n",
    "\n",
    "    def run (self):\n",
    "        print(\"Retrieving %s\", self.source)\n",
    "        \n",
    "        try:\n",
    "            remotefile = urllib.request.urlopen(self.source)\n",
    "            localfile = open(self.output,'wb')\n",
    "            localfile.write(remotefile.read())\n",
    "            localfile.close()\n",
    "            remotefile.close()\n",
    "        except Exception as e:\n",
    "            print(\"%s with error %s\", self.source, e)\n",
    "            pass\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KKI.001.002.tar.gz\n",
      "KKI_phenotypic.csv\n",
      "NeuroIMAGE.001.001.tar.gz\n",
      "NeuroIMAGE_phenotypic.csv\n",
      "ADHD200_Combined_TestRelease.001.001.tar.gz\n",
      "NYU.001.001.part3.tar.gz\n",
      "NYU.001.001.part4.tar.gz\n",
      "NYU.001.002.part1.tar.gz\n",
      "NYU.001.002.part2.tar.gz\n",
      "NYU_phenotypic.csv\n",
      "OHSU.001.004.tar.gz\n",
      "OHSU_phenotypic.csv\n",
      "Peking_1.001.003.tar.gz\n",
      "Peking_1_phenotypic.csv\n",
      "Peking_2.001.001.tar.gz\n",
      "Peking_2_phenotypic.csv\n",
      "Peking_3.001.001.tar.gz\n",
      "Peking_3_phenotypic.csv\n",
      "Pittsburgh.001.001.tar.gz\n",
      "Pittsburgh_phenotypic.csv\n",
      "WashU.001.001.tar.gz\n",
      "WashU.Update.tar.gz\n",
      "WashU_phenotypic.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "sources = np.genfromtxt('adhddata.urls',dtype=object).tolist()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "datadir = os.path.join(cwd, 'data')\n",
    "runningCount = 0\n",
    "\n",
    "for source in sources:\n",
    "    source = source.decode(\"utf-8\") \n",
    "    filename = source.split('/')[-1]\n",
    "    output = os.path.join(datadir, filename)\n",
    "\n",
    "    print(filename)\n",
    "    if not os.path.exists(output):\n",
    "        if runningCount == 2: # use two thread at most\n",
    "            parent.join()\n",
    "            runningCount = 0 \n",
    "        parent = Parent(source, output)\n",
    "        parent.start()\n",
    "        runningCount += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "def binary_search(pheno, id, rowCount):\n",
    "    min = 1\n",
    "    max = rowCount - 1\n",
    "    print(id)\n",
    "    while True:\n",
    "        if max < min:\n",
    "            print(\"NOT found!\")\n",
    "            return -1\n",
    "        m = (min + max) // 2\n",
    "        line = linecache.getline(pheno,m)\n",
    "        ele = line.split(\",\")\n",
    "        if(ele[0] == \"ScanDir ID\"):\n",
    "            min = m + 1\n",
    "        elif int(ele[0]) < int(id):\n",
    "            min = m + 1\n",
    "        elif int(ele[0]) > int(id):\n",
    "            max = m - 1\n",
    "        else:\n",
    "            print(\"found!\")\n",
    "            return ele[5]\n",
    "        \n",
    "import sys\n",
    "import threading\n",
    "import urllib\n",
    "class Parent_extract (threading.Thread):\n",
    "\n",
    "    def __init__(self, source, datadir):\n",
    "        \"\"\"Documentation\"\"\"\n",
    "        threading.Thread.__init__(self)\n",
    "        self.source = source\n",
    "        self.datadir = datadir\n",
    "\n",
    "    def run (self):\n",
    "        try:\n",
    "            filename = source.split('/')[-1]\n",
    "            location = os.path.join(datadir, filename)\n",
    "            print(filename)\n",
    "            siteId = filename.split('.')[0]\n",
    "            pheFileName = siteId+\"_phenotypic.csv\"\n",
    "            print(pheFileName)\n",
    "            pheno = os.path.join(datadir, pheFileName)\n",
    "            rowCount = 0\n",
    "            with open(pheno, \"r\") as f:\n",
    "                reader = csv.reader(f, delimiter=\"\\t\")\n",
    "                for i, line in enumerate(reader):\n",
    "                    rowCount=rowCount+1\n",
    "            print(rowCount)\n",
    "\n",
    "            try:\n",
    "                tar = tarfile.open(location, mode='r')\n",
    "            except Exception as e:\n",
    "                print(\"Error\", location, e)\n",
    "                pass\n",
    "            for name in tar.getnames():\n",
    "                if 'gz' in name:\n",
    "                    src, id = name.split('/')[0:2]\n",
    "                    scantype = name.split('/')[-2]\n",
    "                    if(\"res\" not in scantype): \n",
    "                        continue\n",
    "                    id = id.lstrip('0')\n",
    "                    id = int(id)\n",
    "                    phenotype = binary_search(pheno, id, rowCount)\n",
    "                    if(phenotype == \"0\"):\n",
    "                         type = 0\n",
    "                    else:\n",
    "                        type = 1\n",
    "                    seq = (str(id), str(type), '%s.nii.gz'%scantype);\n",
    "                    outfile = '_'.join(seq)\n",
    "                    if 'TestRelease' in source:\n",
    "                        outfile = os.path.join(testdatadir, outfile)\n",
    "                    else:\n",
    "                        outfile = os.path.join(traindatadir, outfile)\n",
    "                    if not os.path.exists(outfile):\n",
    "                        print(id, name, outfile)\n",
    "                        print(\"Extracting...\")\n",
    "                        tar.extract(name, tempdir)\n",
    "                        shutil.move(os.path.join(tempdir, name),\n",
    "                                    outfile)\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(\"%s with error %s\", self.source, e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KKI.001.002.tar.gz\n",
      "KKI_phenotypic.csv\n",
      "84\n",
      "1018959\n",
      "42\n",
      "2740232,3,1,11.09,1,0,,2,42,43,48,1,99,102,N/A,85,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "2740232\n",
      "21\n",
      "1988015,3,1,11.17,1,0,Simple Phobia,2,46,44,50,1,100,108,N/A,99,2,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1988015\n",
      "10\n",
      "1623716,3,0,12.65,1,1,,2,87,90,90,1,89,88,N/A,89,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1623716\n",
      "5\n",
      "1266183,3,0,9.67,1,0,,2,47,44,43,1,128,106,N/A,120,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1266183\n",
      "2\n",
      "1018959,3,0,12.36,1,0,,2,44,47,44,1,121,100,N/A,110,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1018959\n",
      "found!\n",
      "0\n",
      "1018959_0_rest_1.nii.gz\n",
      "NeuroIMAGE.001.001.tar.gz\n",
      "NeuroIMAGE_phenotypic.csv\n",
      "49\n",
      "1017176\n",
      "24\n",
      "3190461,4,1,19.88,1,2,,,,,,,,,,,,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "3190461\n",
      "12\n",
      "2074737,4,1,14.09,1,2,,,,,,,,,,,,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "2074737\n",
      "6\n",
      "1411495,4,0,15.21,1,0,,,,,,,,,,,,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1411495\n",
      "3\n",
      "1125505,4,1,19.3,1,0,,,,,,,,,,,,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1125505\n",
      "1\n",
      "ScanDir ID,Site,Gender,Age,Handedness,DX,Secondary Dx ,ADHD Measure,ADHD Index,Inattentive,Hyper/Impulsive,IQ Measure,Verbal IQ,Performance IQ,Full2 IQ,Full4 IQ,Med Status,QC_Rest_1,QC_Rest_2,QC_Rest_3,QC_Rest_4,QC_Anatomical_1,QC_Anatomical_2\n",
      "\n",
      "ScanDir ID\n",
      "2\n",
      "1017176,4,0,11.66,1,0,,,,,,,,,,,,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1017176\n",
      "found!\n",
      "0\n",
      "1017176_0_rest_1.nii.gz\n",
      "NYU.001.001.part3.tar.gz\n",
      "NYU_phenotypic.csv\n",
      "223\n",
      "1000804\n",
      "111\n",
      "10110,5,0,16.08,0.57,0,,2,47,43,43,2,99,97,N/A,99,1,1,1,N/A,N/A,1,1\n",
      "\n",
      "10110\n",
      "167\n",
      "2570769,5,1,13.49,1,1,dyslexia; dysgraphia,2,75,70,66,2,88,82,N/A,84,2,1,1,N/A,N/A,1,1\n",
      "\n",
      "2570769\n",
      "139\n",
      "1320247,5,1,8.59,0.21,0,,2,43,41,48,2,131,108,N/A,122,1,1,1,N/A,N/A,1,1\n",
      "\n",
      "1320247\n",
      "125\n",
      "10124,5,0,14.06,0.62,0,,2,44,43,44,2,109,119,N/A,115,1,1,1,N/A,N/A,1,1\n",
      "\n",
      "10124\n",
      "132\n",
      "1023964,5,1,8.29,0.57,3,,2,60,56,48,2,115,125,N/A,123,-999,1,0,N/A,N/A,1,1\n",
      "\n",
      "1023964\n",
      "128\n",
      "10127,5,1,8.14,0.04,1,,2,77,79,74,2,132,121,N/A,130,-999,N/A,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "10127\n",
      "130\n",
      "10129,5,0,8.39,0.38,3,,2,67,71,47,2,-999,-999,N/A,-999,1,1,1,N/A,N/A,1,N/A\n",
      "\n",
      "10129\n",
      "131\n",
      "1000804,5,1,7.29,0.83,0,,2,40,41,41,2,112,103,N/A,109,1,1,0,N/A,N/A,1,N/A\n",
      "\n",
      "1000804\n",
      "found!\n",
      "0\n",
      "1000804_0_rest_1.nii.gz\n",
      "1000804 NYU/1000804/session_1/rest_1/rest.nii.gz F:\\ece\\capstone\\code\\py\\data\\adhd\\traindata\\1000804_0_rest_1.nii.gz\n",
      "Extracting...\n",
      "NYU.001.001.part4.tar.gz\n",
      "NYU_phenotypic.csv\n",
      "223\n",
      "3011311\n",
      "111\n",
      "10110,5,0,16.08,0.57,0,,2,47,43,43,2,99,97,N/A,99,1,1,1,N/A,N/A,1,1\n",
      "\n",
      "10110\n",
      "167\n",
      "2570769,5,1,13.49,1,1,dyslexia; dysgraphia,2,75,70,66,2,88,82,N/A,84,2,1,1,N/A,N/A,1,1\n",
      "\n",
      "2570769\n",
      "195\n",
      "3653737,5,1,9.38,0.24,1,,2,63,61,66,2,106,104,N/A,106,-999,1,0,N/A,N/A,1,1\n",
      "\n",
      "3653737\n",
      "181\n",
      "3163200,5,1,11.91,1,0,,2,49,50,46,2,120,117,N/A,121,1,1,0,N/A,N/A,1,1\n",
      "\n",
      "3163200\n",
      "174\n",
      "2854839,5,0,9.17,0.45,3,,2,71,76,50,2,116,126,N/A,124,-999,1,1,N/A,N/A,1,1\n",
      "\n",
      "2854839\n",
      "177\n",
      "2983819,5,0,12.28,0.68,3,Central Auditory Processing Disorder (by history); MDD in remission; r/o GAD; Anxiety disorder NOS; Dysthymia; Depression NOS,2,90,90,80,2,108,103,N/A,107,-999,1,1,N/A,N/A,1,N/A\n",
      "\n",
      "2983819\n",
      "179\n",
      "2996531,5,1,12.62,0.83,3,mild anxiety  and depressive sx,2,72,72,72,2,137,119,N/A,132,-999,1,1,N/A,N/A,1,1\n",
      "\n",
      "2996531\n",
      "180\n",
      "3011311,5,0,11.56,0.75,0,,2,47,44,43,2,115,91,N/A,103,1,1,1,N/A,N/A,1,1\n",
      "\n",
      "3011311\n",
      "found!\n",
      "0\n",
      "3011311_0_rest_1.nii.gz\n",
      "3011311 NYU/3011311/session_1/rest_1/rest.nii.gz F:\\ece\\capstone\\code\\py\\data\\adhd\\traindata\\3011311_0_rest_1.nii.gz\n",
      "Extracting...\n",
      "NYU.001.002.part1.tar.gz\n",
      "NYU_phenotypic.csv\n",
      "223\n",
      "10001\n",
      "111\n",
      "10110,5,0,16.08,0.57,0,,2,47,43,43,2,99,97,N/A,99,1,1,1,N/A,N/A,1,1\n",
      "\n",
      "10110\n",
      "55\n",
      "10054,5,1,17.83,-999,0,,2,53,45,49,2,-999,-999,N/A,-999,1,1,1,N/A,N/A,1,N/A\n",
      "\n",
      "10054\n",
      "27\n",
      "10026,5,1,11.73,0.81,1,,2,68,56,76,2,132,123,N/A,131,-999,1,1,N/A,N/A,1,1\n",
      "\n",
      "10026\n",
      "13\n",
      "10012,5,0,12.41,0.42,1,,2,82,67,74,2,102,97,N/A,100,-999,1,0,N/A,N/A,1,1\n",
      "\n",
      "10012\n",
      "6\n",
      "10005,5,1,11.92,0.68,2,,2,63,59,70,2,98,118,N/A,108,2,0,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "10005\n",
      "3\n",
      "10002,5,0,13.24,0.52,3,LD,2,66,65,62,2,65,89,N/A,75,2,1,1,N/A,N/A,1,N/A\n",
      "\n",
      "10002\n",
      "1\n",
      "ScanDir ID,Site,Gender,Age,Handedness,DX,Secondary Dx ,ADHD Measure,ADHD Index,Inattentive,Hyper/Impulsive,IQ Measure,Verbal IQ,Performance IQ,Full2 IQ,Full4 IQ,Med Status,QC_Rest_1,QC_Rest_2,QC_Rest_3,QC_Rest_4,QC_Anatomical_1,QC_Anatomical_2\n",
      "\n",
      "ScanDir ID\n",
      "2\n",
      "10001,5,0,11.17,0.52,3,,2,90,90,80,2,106,91,N/A,99,-999,1,1,N/A,N/A,1,N/A\n",
      "\n",
      "10001\n",
      "found!\n",
      "3\n",
      "10001_1_rest_1.nii.gz\n",
      "10001 NYU/0010001/session_1/rest_1/rest.nii.gz F:\\ece\\capstone\\code\\py\\data\\adhd\\traindata\\10001_1_rest_1.nii.gz\n",
      "Extracting...\n",
      "NYU.001.002.part2.tar.gz\n",
      "NYU_phenotypic.csv\n",
      "223\n",
      "10060\n",
      "111\n",
      "10110,5,0,16.08,0.57,0,,2,47,43,43,2,99,97,N/A,99,1,1,1,N/A,N/A,1,1\n",
      "\n",
      "10110\n",
      "55\n",
      "10054,5,1,17.83,-999,0,,2,53,45,49,2,-999,-999,N/A,-999,1,1,1,N/A,N/A,1,N/A\n",
      "\n",
      "10054\n",
      "83\n",
      "10082,5,1,11.4,0.73,0,,2,43,44,44,2,141,133,N/A,142,1,1,0,N/A,N/A,1,1\n",
      "\n",
      "10082\n",
      "69\n",
      "10068,5,1,13.3,0.5,0,,2,-999,-999,-999,-999,-999,-999,N/A,-999,1,1,1,N/A,N/A,1,1\n",
      "\n",
      "10068\n",
      "62\n",
      "10061,5,1,11.41,1,3,Adjustment Disorder with Depressed Mood,2,79,79,68,2,99,103,N/A,101,1,0,N/A,N/A,N/A,0,0\n",
      "\n",
      "10061\n",
      "58\n",
      "10057,5,1,17.7,0.68,0,,2,40,40,46,2,111,92,N/A,102,1,1,1,N/A,N/A,1,1\n",
      "\n",
      "10057\n",
      "60\n",
      "10059,5,0,17.89,1,0,,2,45,45,55,2,127,124,N/A,128,1,1,1,N/A,N/A,1,1\n",
      "\n",
      "10059\n",
      "61\n",
      "10060,5,1,8.75,0.67,1,Autistic traits,2,76,79,67,2,93,104,N/A,99,2,0,N/A,N/A,N/A,1,1\n",
      "\n",
      "10060\n",
      "found!\n",
      "1\n",
      "10060_1_rest_1.nii.gz\n",
      "10060 NYU/0010060/session_1/rest_1/rest.nii.gz F:\\ece\\capstone\\code\\py\\data\\adhd\\traindata\\10060_1_rest_1.nii.gz\n",
      "Extracting...\n",
      "OHSU.001.004.tar.gz\n",
      "OHSU_phenotypic.csv\n",
      "80\n",
      "Error F:\\ece\\capstone\\code\\py\\data\\OHSU.001.004.tar.gz file could not be opened successfully\n",
      "%s with error %s ftp://www.nitrc.org/fcon_1000/htdocs/indi/adhd200/sites/ohsu/data/OHSU.001.004.tar.gz local variable 'tar' referenced before assignment\n",
      "Peking_1.001.003.tar.gz\n",
      "Peking_1_phenotypic.csv\n",
      "86\n",
      "1056121\n",
      "43\n",
      "3086074,1,1,11.5,1,0,,1,36,20,16,3,121,124,N/A,125,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "3086074\n",
      "21\n",
      "1912810,1,0,10.33,1,0,,1,-999,-999,-999,3,130,118,N/A,128,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1912810\n",
      "10\n",
      "1302449,1,0,8.58,1,0,,1,21,11,10,3,126,108,N/A,120,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1302449\n",
      "5\n",
      "1139030,1,0,11.33,1,0,,1,32,18,14,3,90,86,N/A,87,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1139030\n",
      "2\n",
      "1056121,1,1,13.92,1,0,,1,30,15,15,3,126,136,N/A,135,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1056121\n",
      "found!\n",
      "0\n",
      "1056121_0_rest_1.nii.gz\n",
      "1056121 Peking_1/1056121/session_1/rest_1/rest.nii.gz F:\\ece\\capstone\\code\\py\\data\\adhd\\traindata\\1056121_0_rest_1.nii.gz\n",
      "Extracting...\n",
      "Peking_2.001.001.tar.gz\n",
      "Peking_2_phenotypic.csv\n",
      "68\n",
      "1050975\n",
      "34\n",
      "2950754,1,1,13.33,1,1,,1,51,22,29,3,137,109,N/A,127,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "2950754\n",
      "17\n",
      "1916266,1,1,13.17,1,0,,1,29,20,9,3,124,109,N/A,119,1,-999,N/A,N/A,N/A,-999,N/A\n",
      "\n",
      "1916266\n",
      "8\n",
      "1177160,1,0,10.5,1,0,,1,23,13,10,3,142,124,N/A,138,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1177160\n",
      "4\n",
      "1093743,1,1,11.92,1,0,,1,20,11,9,3,125,120,N/A,125,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1093743\n",
      "2\n",
      "1050975,1,1,13.58,1,0,,1,28,17,11,3,125,135,N/A,133,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1050975\n",
      "found!\n",
      "0\n",
      "1050975_0_rest_1.nii.gz\n",
      "1050975 Peking_2/1050975/session_1/rest_1/rest.nii.gz F:\\ece\\capstone\\code\\py\\data\\adhd\\traindata\\1050975_0_rest_1.nii.gz\n",
      "Extracting...\n",
      "Peking_3.001.001.tar.gz\n",
      "Peking_3_phenotypic.csv\n",
      "43\n",
      "1050345\n",
      "21\n",
      "2940712,1,1,13.08,1,3,LD,1,36,22,14,3,124,73,N/A,110,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "2940712\n",
      "10\n",
      "1794770,1,1,11.75,1,0,,1,39,24,15,3,87,85,N/A,84,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1794770\n",
      "5\n",
      "1399863,1,1,12.83,1,1,\"ODD, LD\",1,64,29,35,3,103,85,N/A,94,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1399863\n",
      "2\n",
      "1050345,1,1,12.67,1,0,,1,24,12,12,3,124,127,N/A,128,1,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "1050345\n",
      "found!\n",
      "0\n",
      "1050345_0_rest_1.nii.gz\n",
      "1050345 Peking_3/1050345/session_1/rest_1/rest.nii.gz F:\\ece\\capstone\\code\\py\\data\\adhd\\traindata\\1050345_0_rest_1.nii.gz\n",
      "Extracting...\n",
      "Pittsburgh.001.001.tar.gz\n",
      "Pittsburgh_phenotypic.csv\n",
      "90\n",
      "16001\n",
      "45\n",
      "16044,7,1,14.85,1,0,,N/A,N/A,N/A,N/A,2,88,81,83,82,,0,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "16044\n",
      "22\n",
      "16021,7,1,12.41,1,0,,N/A,N/A,N/A,N/A,2,-999,-999,-999,133,,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "16021\n",
      "11\n",
      "16010,7,1,11.24,1,0,,N/A,N/A,N/A,N/A,2,118,131,127,123,,1,N/A,N/A,N/A,1,N/A\n",
      "\n",
      "16010\n",
      "5\n",
      "16004,7,1,10.49,1,0,,N/A,N/A,N/A,N/A,2,95,105,100,104,,1,N/A,N/A,N/A,0,N/A\n",
      "\n",
      "16004\n",
      "2\n",
      "16001,7,1,10.11,1,0,,N/A,N/A,N/A,N/A,2,88,131,108,106,,1,N/A,N/A,N/A,0,N/A\n",
      "\n",
      "16001\n",
      "found!\n",
      "0\n",
      "16001_0_rest_1.nii.gz\n",
      "16001 Pittsburgh/0016001/session_1/rest_1/rest.nii.gz F:\\ece\\capstone\\code\\py\\data\\adhd\\traindata\\16001_0_rest_1.nii.gz\n",
      "Extracting...\n",
      "WashU.001.001.tar.gz\n",
      "WashU_phenotypic.csv\n",
      "62\n",
      "15001\n",
      "31\n",
      "15031,8,1,12.35,1,0,,N/A,N/A,N/A,N/A,4,N/A,N/A,N/A,120,N/A,3,0,0,1,N/A,N/A,N/A,1,N/A,N/A,N/A\n",
      "\n",
      "15031\n",
      "15\n",
      "15015,8,0,8.1,1,0,,N/A,N/A,N/A,N/A,4,N/A,N/A,N/A,109,N/A,2,0,N/A,N/A,N/A,N/A,N/A,1,N/A,N/A,N/A\n",
      "\n",
      "15015\n",
      "7\n",
      "15006,8,0,21.81,1,0,,N/A,N/A,N/A,N/A,4,N/A,N/A,N/A,128,N/A,2,1,1,N/A,N/A,N/A,N/A,1,1,0,N/A\n",
      "\n",
      "15006\n",
      "3\n",
      "15002,8,0,7.17,1,0,,N/A,N/A,N/A,N/A,4,N/A,N/A,N/A,136,N/A,1,1,0,0,0,0,0,1,N/A,N/A,N/A\n",
      "\n",
      "15002\n",
      "1\n",
      "ScanDirID,Site,Gender,Age,Handedness,DX,Secondary Dx ,ADHD Measure,ADHD Index,Inattentive,Hyper/Impulsive,IQ Measure,Verbal IQ,Performance IQ,Full2 IQ,Full4 IQ,Med Status,Study #,QC_S1_Rest_1,QC_S1_Rest_2,QC_S1_Rest_3,QC_S1_Rest_4,QC_S1_Rest_5,QC_S1_Rest_6,QC_S1_Anat,QC_S2_Rest_1,QC_S2_Rest_2,QC_S2_Anat\n",
      "\n",
      "ScanDirID\n",
      "%s with error %s ftp://www.nitrc.org/fcon_1000/htdocs/indi/adhd200/sites/washu/data/WashU.001.001.tar.gz invalid literal for int() with base 10: 'ScanDirID'\n",
      "WashU.Update.tar.gz\n",
      "WashU_phenotypic.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import tarfile\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "sources = np.genfromtxt('adhddata.urls',dtype=object).tolist()\n",
    "cwd = os.getcwd()\n",
    "datadir = os.path.join(cwd, 'data')\n",
    "adhddir = os.path.join(datadir, 'adhd')\n",
    "traindatadir = os.path.join(adhddir, 'traindata')\n",
    "testdatadir = os.path.join(adhddir, 'testdata')\n",
    "tempdir = os.path.join(datadir, 'temp')\n",
    "runningCount = 0\n",
    "for source in sources:\n",
    "    source = source.decode(\"utf-8\") \n",
    "    if 'tar.gz' in source and 'Combined_T' not in source:\n",
    "        if runningCount == 1: # use four thread at most\n",
    "            parent.join()\n",
    "            runningCount = 0 \n",
    "        parent = Parent_extract(source, datadir)\n",
    "        parent.start()\n",
    "        runningCount += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
